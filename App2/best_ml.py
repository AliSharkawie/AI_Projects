# -*- coding: utf-8 -*-
"""best ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x3In3dIJvA_AaFgnNKHOPu8pSSfYpQuT
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import shutil

!pip install opendatasets
!pip install pandas

import opendatasets as od
import pandas
od.download("https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset")
# {"username":"alsharkawy","key":"06a141443ba6c29eb8c2317c9fe83b1e"}

# https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-
# dataset/download?datasetVersionNumber=1

import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Load the data
base_dir = "/content/microsoft-catsvsdogs-dataset"
train_dir = os.path.join(base_dir, "PetImages")
test_dir = os.path.join(base_dir, "PetImages")

# Data preprocessing
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Load the pre-trained VGG-16 model without dense layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add your own dense layers and classification layer
model = Sequential([
    base_model,
    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model with custom loss and optimizer
model.compile(optimizer=Adam(learning_rate=0.1),
              loss=BinaryCrossentropy(),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    epochs=3,
                    validation_data=test_generator,
                    validation_steps=len(test_generator))

# UnFreeze the base model layers
# for layer in base_model.layers:
#     layer.trainable = True

# # Compile the model with custom loss and optimizer
# model.compile(optimizer=Adam(learning_rate=0.1),
#               loss=BinaryCrossentropy(),
#               metrics=['accuracy'])

# # Train the model
# history = model.fit(train_generator,
#                     steps_per_epoch=len(train_generator),
#                     epochs=5,
#                     validation_data=test_generator,
#                     validation_steps=len(test_generator))

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

cat_dir = "/content/microsoft-catsvsdogs-dataset/PetImages/Cat"
i = 0
cat_images = os.listdir(cat_dir)
for image in (cat_images):
    i +=1
    print(image)
    old_name = os.path.join(cat_dir, image)
    print(old_name)
    if i > 10 : break

# the best one
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Load the data
base_dir = "/content/microsoft-catsvsdogs-dataset/PetImages"
# train_dir = os.path.join(base_dir, "PetImages")
# test_dir = os.path.join(base_dir, "PetImages")

# base_dir = "/content/microsoft-catsvsdogs-dataset/PetImages"
# # cat_dir = os.path.join(base_dir, "Cat")
# # dog_dir = os.path.join(base_dir, "Dog")

cat_dir = "/content/microsoft-catsvsdogs-dataset/PetImages/Cat"
dog_dir = "/content/microsoft-catsvsdogs-dataset/PetImages/Dog"

# Create directories for train and test data
train_cat_dir = os.path.join(base_dir, "train_cat")
test_cat_dir = os.path.join(base_dir, "test_cat")
train_dog_dir = os.path.join(base_dir, "train_dog")
test_dog_dir = os.path.join(base_dir, "test_dog")

if os.path.exists(train_dog_dir):
    # Remove the destination directory and its contents
    shutil.rmtree(train_dog_dir)
if os.path.exists(test_dog_dir):
    # Remove the destination directory and its contents
    shutil.rmtree(test_dog_dir)
if os.path.exists(train_cat_dir):
    # Remove the destination directory and its contents
    shutil.rmtree(train_cat_dir)
if os.path.exists(test_cat_dir):
    # Remove the destination directory and its contents
    shutil.rmtree(test_cat_dir)

if not os.path.exists(train_cat_dir):
    os.makedirs(train_cat_dir)
if not os.path.exists(test_cat_dir):
    os.makedirs(test_cat_dir)
if not os.path.exists(train_dog_dir):
    os.makedirs(train_dog_dir)
if not os.path.exists(test_dog_dir):
    os.makedirs(test_dog_dir)

# Move cat images to train and test directories
# cat_images = os.listdir(cat_dir)
# Ù…ist of files and directories in the specified directory
i = 0
cat_images = os.listdir(cat_dir)
for image in (cat_images):
    i +=1
    old_name = os.path.join(cat_dir, image)
    # new_name = os.path.join(train_dir, f"Cat_{image}")  # Example: "image_1.jpg", "image_2.jpg", etc.
    #os.rename(old_name, new_name)
    #image = new_name
    #src = os.path.join(cat_dir,image)
    src = old_name
    if i < 1000:
        dst = os.path.join(train_cat_dir)
    else:
        dst = os.path.join(test_cat_dir)
    shutil.copy(src, dst)
    if i > 1500: break
# Move dog images to train and test directories
dog_images =  os.listdir(dog_dir)
i=0
for image in (dog_images):
    i +=1
    old_name = os.path.join(dog_dir, image)
    # new_name = os.path.join(dog_dir, f"Dog_{image}")  # Example: "image_1.jpg", "image_2.jpg", etc.
    # os.rename(old_name, new_name)
    # image = new_name
    # src = os.path.join(dog_dir,image)
    src = old_name
    if i < 1000:
        dst = os.path.join(train_dog_dir)
    else:
        dst = os.path.join(test_dog_dir)
    shutil.copy(src, dst)
    if i > 1500: break



# Data preprocessing
# all_train = os.join(base_dir, "all_train")
# all_test = os.join(base_dir, "all_test")

print("base_dir: ", base_dir)
all_train = (base_dir + "/all_train")
all_test =  (base_dir + "/all_test")
print("all test: ", all_test)

if os.path.exists(all_train):
    shutil.rmtree(all_train)
if os.path.exists(all_test):
    shutil.rmtree(all_test)

if not os.path.exists(all_train):
    os.makedirs(all_train)
if not os.path.exists(all_test):
    os.makedirs(all_test)

################################################################

if os.path.exists(all_train + "/Cat"):
    shutil.rmtree(all_train + "/Cat")
if os.path.exists(all_test + "/Dog"):
    shutil.rmtree(all_test + "/Dog")
if os.path.exists(all_train + "/Dog"):
    shutil.rmtree(all_train + "/Dog")
if os.path.exists(all_test + "/Cat"):
    shutil.rmtree(all_test + "/Cat")

if not os.path.exists(all_train + "/Cat"):
    os.makedirs(all_train + "/Cat")
if not os.path.exists(all_train + "/Dog"):
    os.makedirs(all_train + "/Dog")
if not os.path.exists(all_test + "/Cat"):
    os.makedirs(all_test + "/Cat")
if not os.path.exists(all_test + "/Dog"):
    os.makedirs(all_test + "/Dog")


# folder in dolder in folder ( 3 ) in all
shutil.copytree(train_dog_dir, all_train + "/Dog", dirs_exist_ok=True)
shutil.copytree(train_cat_dir, all_train + "/Cat", dirs_exist_ok=True)
shutil.copytree(test_dog_dir, all_test + "/Cat", dirs_exist_ok=True)
shutil.copytree(test_cat_dir, all_test + "/Dog", dirs_exist_ok=True)

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    all_train,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    all_test,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Load the pre-trained VGG-16 model without dense layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add your own dense layers and classification layer
model = Sequential([
    base_model,
    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model with custom loss and optimizer
model.compile(optimizer=Adam(learning_rate=0.1),
              loss=BinaryCrossentropy(),
              metrics=['accuracy'])

# Train the model
# steps_per_epoch=len(train_generator),
history = model.fit(train_generator,
                    epochs=5,
                    validation_data=test_generator,
                    validation_steps=len(test_generator))

# UnFreeze the base model layers
# for layer in base_model.layers:
#     layer.trainable = True

# # Compile the model with custom loss and optimizer
# model.compile(optimizer=Adam(learning_rate=0.1),
#               loss=BinaryCrossentropy(),
#               metrics=['accuracy'])

# # Train the model
# history = model.fit(train_generator,
#                     steps_per_epoch=len(train_generator),
#                     epochs=5,
#                     validation_data=test_generator,
#                     validation_steps=len(test_generator))

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")